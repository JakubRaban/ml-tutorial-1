{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupa\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zagadnienie 5 - zmiana miar jakości klasyfikatora przy zmniejszaniu zbioru uczącego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zagadnienie 6 - Augumentacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augumentacja jest techniką pozyskiwania dodatkowych danych do trenowania modelu na podstawie już istniejących danych poprzez aproksymację, inter- i ekstrapolację, przekształcenie itp. Potrafi znacznie poprawić dokładność modelu w sytuacji, gdy zbiór danych nie jest wystarczająco duży."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla przykładu prosta augumentacja obrazu może polegać na dodaniu do zbioru treningowego dodatkowych kopii tego obrazu uzyskiwanych przez przekształcenia takie jak: obrót, przybliżenie/oddalenie, przycięcie, dodanie szumu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prosty przykład procedury przekształcającej obraz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedura obracająca obraz wzdłóż poziomej osi symetrii (obraz przechowywany jako dwuwymiarowa tablica numpy)\n",
    "import numpy as np\n",
    "def flip(image):\n",
    "    height, width = image.shape\n",
    "    flipped_image = np.ndarray(shape=(height, width), dtype=int)\n",
    "    for row in range(height):\n",
    "        flipped_image[row] = image[height - row - 1]\n",
    "    return flipped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oryginalny obraz\n",
      "[[ 1  2  3  4  3  2]\n",
      " [ 5  6  7  8  7  6]\n",
      " [ 9 10 11 12 11 10]\n",
      " [13 14 15 16 15 14]]\n",
      "Odwrócony obraz\n",
      "[[13 14 15 16 15 14]\n",
      " [ 9 10 11 12 11 10]\n",
      " [ 5  6  7  8  7  6]\n",
      " [ 1  2  3  4  3  2]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[1,2,3,4,3,2],\n",
    "                  [5,6,7,8,7,6],\n",
    "                  [9,10,11,12,11,10],\n",
    "                  [13,14,15,16,15,14]])\n",
    "\n",
    "print(\"Oryginalny obraz\")\n",
    "print(image)\n",
    "print(\"Odwrócony obraz\")\n",
    "print(flip(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można by stwierdzić, że nikt nie będzie próbował dokonywać klasyfikowacji odwróconego zdjęcia, np. człowieka.<br>\n",
    "Jednak czy aby na pewno jest ono zupełnie nieprzydatne do celu zwiększenia dokładności modelu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](stanie-na-rekach.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak bardzo augumentacja poprawia model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujemy skorzystać z niewielkiego zbioru danych, dodać augumentację i sprawdzić czy dokładność modelu poprawiła się."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "# Czy rzecz tak prosta jak dodanie kilku losowych czarno-białych pikseli może pomóc zwiększyć dokładność?\n",
    "def augument(images):\n",
    "    aug = iaa.Sequential([\n",
    "        iaa.SaltAndPepper(0.1)\n",
    "    ])\n",
    "    return aug(images=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 784) (1050, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Użyjemy tylko 700 z 70000 obrazków w MNIST\n",
    "mnist_small, mnist_small_target = mnist_frame[:700], mnist_target[:700]\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_small, mnist_small_target, train_size=0.75, random_state=0)\n",
    "X_train_aug, y_train_aug = np.reshape(np.copy(X_train), (-1, 28, 28)), np.concatenate([y_train, y_train])\n",
    "\n",
    "# Dla każdego obrazka z X_train dokładamy nowy, zaugumentowany\n",
    "for aug_img in augument([np.reshape(x, (28,28,1)) for x in np.array(X_train, dtype='uint8')]):\n",
    "    X_train_aug = np.append(X_train_aug, np.reshape(aug_img, (1,28,28)), axis=0)\n",
    "\n",
    "X_train_aug = np.reshape(X_train_aug, (-1, 784))\n",
    "    \n",
    "params = {\n",
    "  'n_neighbors': (2, 3, 5),\n",
    "  'weights': ('uniform', 'distance')\n",
    "}\n",
    "knn = KNeighborsClassifier(algorithm='auto')\n",
    "clf = GridSearchCV(knn, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457142857142858"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sprawdzenie dokładności bez augumentacji\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_best = clf.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628571428571429"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sprawdzenie dokładności po augumentacji\n",
    "clf.fit(X_train_aug, y_train_aug)\n",
    "y_pred_best = clf.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_pred_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodanie do modelu nowych obrazów z szumem \"salt and pepper\" pomogło poprawić model<br>\n",
    "Widzimy że nawet bardzo prosta augumentacja potrafi zwiększyć dokładność modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tut",
   "language": "python",
   "name": "ml-tut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
